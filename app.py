import streamlit as st
import pandas as pd
import re
from datetime import datetime
import io

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Procesador de Liquidaci√≥n y MASTERDATA",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

def limpiar_columnas_duplicadas(df):
    """
    Elimina columnas duplicadas de un DataFrame
    """
    if df is None or df.empty:
        return df
    
    # Verificar si hay columnas duplicadas
    if df.columns.duplicated().any():
        st.warning(f"‚ö†Ô∏è Columnas duplicadas encontradas: {df.columns[df.columns.duplicated()].tolist()}")
        
        # Eliminar columnas duplicadas (mantener la primera)
        df_limpio = df.loc[:, ~df.columns.duplicated()]
        
        st.success(f"‚úÖ DataFrame limpiado: {len(df.columns)} -> {len(df_limpio.columns)} columnas")
        return df_limpio
    
    return df

def parsear_recibo_liquidacion(contenido_archivo):
    """
    Parsea un archivo de recibos de liquidaci√≥n con formato espec√≠fico
    """
    empleados = []
    empleado_actual = {}
    
    lineas = contenido_archivo.split('\n')
    
    for i, linea in enumerate(lineas):
        linea = linea.strip()
        
        # Nueva p√°gina o nuevo empleado
        if linea.startswith('Pagina:'):
            if empleado_actual:  # Guardar empleado anterior si existe
                empleados.append(empleado_actual.copy())
                empleado_actual = {}
            continue
        
        # Saltar l√≠neas vac√≠as y encabezados
        if not linea or linea.startswith('RECIBO DE PAGO') or linea.startswith('Fecha:'):
            continue
        
        # Extraer informaci√≥n del empleado
        try:
            # N√∫mero de personal y c√©dula
            if 'Nm. Personal' in linea and 'Cedula Ident' in linea:
                personal_match = re.search(r'Nm\. Personal\.+(\d+)', linea)
                cedula_match = re.search(r'Cedula Ident\.+ (\d+)', linea)
                
                if personal_match:
                    empleado_actual['SAP'] = int(personal_match.group(1))
                if cedula_match:
                    empleado_actual['CEDULA'] = int(cedula_match.group(1))
            
            # Nombre del empleado y sueldo b√°sico
            elif 'Empleado' in linea and 'Sueldo Bsico' in linea:
                nombre_match = re.search(r'Empleado \.+ (.+?)\s+Sueldo Bsico\.+\s*([\d\.,]+)', linea)
                if nombre_match:
                    empleado_actual['NOMBRE'] = nombre_match.group(1).strip()
                    sueldo_str = nombre_match.group(2).replace('.', '').replace(',', '.')
                    try:
                        empleado_actual['SALARIO'] = float(sueldo_str)
                    except:
                        empleado_actual['SALARIO'] = 0
            
            # Compa√±√≠a y fecha de nacimiento
            elif 'Compaa' in linea and 'Fecha Nacto' in linea:
                compania_match = re.search(r'Compaa\.+ (.+?)\s+Fecha Nacto\.+(.+)', linea)
                if compania_match:
                    empleado_actual['COMPANIA'] = compania_match.group(1).strip()
                    empleado_actual['FECHA_NACIMIENTO'] = compania_match.group(2).strip()
            
            # Divisi√≥n y fecha de ingreso
            elif 'Divisin' in linea and 'Fecha Ingreso' in linea:
                division_match = re.search(r'Divisin\.+ (.+?)\s+Fecha Ingreso\.+(.+)', linea)
                if division_match:
                    empleado_actual['REGIONAL'] = division_match.group(1).strip()
                    empleado_actual['F_ING'] = division_match.group(2).strip()
            
            # Subdivisi√≥n y relaci√≥n laboral
            elif 'Subdivisin' in linea and 'Relacin Lab' in linea:
                subdivision_match = re.search(r'Subdivisin\.+ (.+?)\s+Relacin Lab\.+(.+)', linea)
                if subdivision_match:
                    empleado_actual['SUBDIVISION'] = subdivision_match.group(1).strip()
                    empleado_actual['CARGO'] = subdivision_match.group(2).strip()
            
            # Centro de coste
            elif 'Ce.coste' in linea:
                ce_coste_match = re.search(r'Ce\.coste\.+(\d+)', linea)
                if ce_coste_match:
                    empleado_actual['CE_COSTE'] = int(ce_coste_match.group(1))
            
            # Buscar conceptos y valores (l√≠neas que terminan con n√∫meros)
            elif re.search(r'^[A-Za-z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë\s\.]+\s+([\d\.,\-]+)$', linea):
                concepto_match = re.match(r'^(.+?)\s+([\d\.,\-]+)$', linea)
                if concepto_match:
                    concepto = concepto_match.group(1).strip()
                    valor_str = concepto_match.group(2).replace('.', '').replace(',', '.')
                    try:
                        valor = float(valor_str)
                        # Limpiar el nombre del concepto
                        concepto_limpio = re.sub(r'[^\w\s]', '', concepto).strip().upper().replace(' ', '_')
                        if concepto_limpio:
                            empleado_actual[f'CONCEPTO_{concepto_limpio}'] = valor
                    except:
                        pass
        
        except Exception as e:
            # Continuar con la siguiente l√≠nea si hay error en el parsing
            continue
    
    # Agregar √∫ltimo empleado
    if empleado_actual:
        empleados.append(empleado_actual)
    
    if len(empleados) == 0:
        return pd.DataFrame()
    
    # Convertir a DataFrame
    df = pd.DataFrame(empleados)
    
    # Calcular valor neto si no existe
    if 'NETO' not in df.columns:
        # Buscar columnas de conceptos para calcular el neto
        conceptos_cols = [col for col in df.columns if col.startswith('CONCEPTO_')]
        if conceptos_cols:
            df['NETO'] = df[conceptos_cols].sum(axis=1, skipna=True)
        elif 'SALARIO' in df.columns:
            df['NETO'] = df['SALARIO']
    
    return df

def procesar_archivos(archivo_liquidacion, archivo_masterdata):
    """
    Procesa los archivos de Liquidaci√≥n y MASTERDATA
    """
    try:
        # 1. Parsear archivo de Liquidaci√≥n
        contenido_liquidacion = archivo_liquidacion.getvalue().decode('utf-8', errors='ignore')
        liquidacion_df = parsear_recibo_liquidacion(contenido_liquidacion)
        
        if liquidacion_df.empty:
            st.error("No se pudieron extraer datos del archivo de liquidaci√≥n")
            return None, None, None
        
        # 2. Leer archivo MASTERDATA
        try:
            masterdata_df = pd.read_excel(archivo_masterdata, engine='openpyxl')
        except:
            try:
                # Si falla openpyxl, intentar con otros motores
                masterdata_df = pd.read_excel(archivo_masterdata)
            except Exception as e:
                st.error(f"Error al leer MASTERDATA: {str(e)}")
                return None, None, None
        
        # 3. Limpiar nombres de columnas
        liquidacion_df.columns = liquidacion_df.columns.str.strip()
        masterdata_df.columns = masterdata_df.columns.str.strip()
        
        # 4. Buscar columnas de uni√≥n
        sap_col_liquidacion = 'SAP' if 'SAP' in liquidacion_df.columns else None
        sap_col_masterdata = 'N¬∫ pers.' if 'N¬∫ pers.' in masterdata_df.columns else None
        
        # 5. Realizar merge si es posible
        if sap_col_liquidacion and sap_col_masterdata:
            liquidacion_df[sap_col_liquidacion] = pd.to_numeric(liquidacion_df[sap_col_liquidacion], errors='coerce')
            masterdata_df[sap_col_masterdata] = pd.to_numeric(masterdata_df[sap_col_masterdata], errors='coerce')
            
            resultado_df = pd.merge(
                liquidacion_df, 
                masterdata_df, 
                left_on=sap_col_liquidacion, 
                right_on=sap_col_masterdata, 
                how='left',
                suffixes=('_liquidacion', '_masterdata')
            )
            
            # ‚úÖ SOLUCI√ìN: Limpiar columnas duplicadas despu√©s del merge
            resultado_df = limpiar_columnas_duplicadas(resultado_df)
            
        else:
            resultado_df = liquidacion_df
            # Tambi√©n limpiar liquidacion_df por si acaso
            resultado_df = limpiar_columnas_duplicadas(resultado_df)
        
        # Tambi√©n limpiar los otros DataFrames
        liquidacion_df = limpiar_columnas_duplicadas(liquidacion_df)
        masterdata_df = limpiar_columnas_duplicadas(masterdata_df)
        
        return resultado_df, liquidacion_df, masterdata_df
        
    except Exception as e:
        st.error(f"Error durante el procesamiento: {str(e)}")
        st.error(f"Detalles del error: {type(e).__name__}")
        import traceback
        st.error(f"Traceback: {traceback.format_exc()}")
        return None, None, None

def crear_excel_descarga(resultado_df, liquidacion_df, masterdata_df):
    """
    Crea un archivo Excel con SOLO 2 hojas: Netos y Convertida
    """
    output = io.BytesIO()
    
    try:
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            
            if resultado_df is not None:
                # Limpiar columnas duplicadas antes de escribir
                resultado_df_limpio = limpiar_columnas_duplicadas(resultado_df)
                
                # ==========================================
                # HOJA 1: "Netos" - EXACTAMENTE como la pediste
                # ==========================================
                
                netos_data = []
                for idx, row in resultado_df_limpio.iterrows():
                    neto_row = {
                        'NETO': row.get('NETO', row.get('SALARIO', 0)),
                        'Valor': row.get('NETO', row.get('SALARIO', 0)),  # Duplicar valor por si necesitas ambas columnas
                        'SAP': row.get('SAP', ''),
                        'C√âDULA': row.get('CEDULA', ''),
                        'NOMBRE': row.get('NOMBRE', ''),
                        'REGIONAL': row.get('REGIONAL', ''),
                        'CE_COSTE': row.get('CE_COSTE', ''),
                        'SALARIO': row.get('SALARIO', ''),
                        'F. ING': row.get('F_ING', ''),
                        'CARGO': row.get('CARGO', ''),
                        'NIVEL': 'Non Manager X-XII'  # Valor por defecto como en tu ejemplo
                    }
                    netos_data.append(neto_row)
                
                if netos_data:
                    netos_df = pd.DataFrame(netos_data)
                    netos_df.to_excel(writer, sheet_name='Netos', index=False)
                
                # ==========================================
                # HOJA 2: "Convertida" - EXACTAMENTE como la pediste  
                # ==========================================
                
                convertida_data = []
                
                # Buscar todas las columnas de conceptos
                conceptos_cols = [col for col in resultado_df_limpio.columns if col.startswith('CONCEPTO_')]
                
                for idx, row in resultado_df_limpio.iterrows():
                    for concepto_col in conceptos_cols:
                        if pd.notna(row[concepto_col]) and row[concepto_col] != 0:
                            # Extraer nombre del concepto sin el prefijo CONCEPTO_
                            concepto_name = concepto_col.replace('CONCEPTO_', '').replace('_', ' ')
                            
                            # Generar c√≥digo basado en el concepto o usar uno por defecto
                            if 'APOYO' in concepto_name.upper() or 'SOSTENIMIENTO' in concepto_name.upper():
                                codigo = 'Y050'
                            else:
                                codigo = 'Y001'  # C√≥digo gen√©rico
                            
                            convertida_row = {
                                'C√ìDIGO': codigo,
                                'CONCEPTO': concepto_name.title(),
                                'CANTIDAD': 30,  # Cantidad por defecto como en tu ejemplo
                                'VALOR': row[concepto_col],
                                'SAP': row.get('SAP', ''),
                                'C√âDULA': row.get('CEDULA', ''),
                                'NOMBRE': row.get('NOMBRE', ''),
                                'SALARIO': row.get('SALARIO', ''),
                                'F. INGRESO': row.get('F_ING', ''),
                                'CARGO': row.get('CARGO', ''),
                                'NIVEL': 'Non Manager X-XII'
                            }
                            convertida_data.append(convertida_row)
                
                # Si no hay conceptos espec√≠ficos, crear filas basadas en salario
                if not convertida_data and len(resultado_df_limpio) > 0:
                    for idx, row in resultado_df_limpio.iterrows():
                        convertida_row = {
                            'C√ìDIGO': 'Y050',
                            'CONCEPTO': 'Apoyo de Sostenimiento',
                            'CANTIDAD': 30,
                            'VALOR': row.get('SALARIO', 0),
                            'SAP': row.get('SAP', ''),
                            'C√âDULA': row.get('CEDULA', ''),
                            'NOMBRE': row.get('NOMBRE', ''),
                            'SALARIO': row.get('SALARIO', ''),
                            'F. INGRESO': row.get('F_ING', ''),
                            'CARGO': row.get('CARGO', ''),
                            'NIVEL': 'Non Manager X-XII'
                        }
                        convertida_data.append(convertida_row)
                
                if convertida_data:
                    convertida_df = pd.DataFrame(convertida_data)
                    convertida_df.to_excel(writer, sheet_name='Convertida', index=False)
                
            else:
                st.error("No hay datos para procesar")
                return None
        
        output.seek(0)
        return output
        
    except Exception as e:
        st.error(f"Error al crear archivo Excel: {str(e)}")
        import traceback
        st.error(f"Traceback completo: {traceback.format_exc()}")
        return None

def main():
    # T√≠tulo principal
    st.title("üìä Procesador de Liquidaci√≥n y MASTERDATA")
    st.markdown("---")
    
    # Descripci√≥n
    st.markdown("""
    ### üéØ ¬øQu√© hace esta aplicaci√≥n?
    Esta herramienta procesa archivos de liquidaci√≥n en formato de recibos de pago y los combina con datos maestros (MASTERDATA) para generar reportes estructurados en Excel.
    
    ### üìã Funcionalidades:
    - ‚úÖ Extrae informaci√≥n de recibos de liquidaci√≥n (formato texto)
    - ‚úÖ Combina con datos de MASTERDATA (Excel/XLSB)
    - ‚úÖ Genera archivo Excel con SOLO 2 hojas espec√≠ficas:
      - **Netos**: NETO, Valor, SAP, C√âDULA, NOMBRE, REGIONAL, CE_COSTE, SALARIO, F. ING, CARGO, NIVEL
      - **Convertida**: C√ìDIGO, CONCEPTO, CANTIDAD, VALOR, SAP, C√âDULA, NOMBRE, SALARIO, F. INGRESO, CARGO, NIVEL
    - ‚úÖ Interfaz web f√°cil de usar
    """)
    
    # Sidebar para carga de archivos
    st.sidebar.header("üìÅ Cargar Archivos")
    
    # Archivo de Liquidaci√≥n
    archivo_liquidacion = st.sidebar.file_uploader(
        "üìÑ Archivo de Liquidaci√≥n (.txt)",
        type=['txt'],
        help="Selecciona el archivo de recibos de liquidaci√≥n en formato texto"
    )
    
    # Archivo MASTERDATA
    archivo_masterdata = st.sidebar.file_uploader(
        "üìä Archivo MASTERDATA (.xlsx)",
        type=['xlsx'],
        help="Selecciona el archivo con los datos maestros (solo formato .xlsx)"
    )
    
    # Bot√≥n de procesamiento
    if st.sidebar.button("üöÄ Procesar Archivos", type="primary"):
        if archivo_liquidacion is not None and archivo_masterdata is not None:
            with st.spinner('‚è≥ Procesando archivos...'):
                resultado_df, liquidacion_df, masterdata_df = procesar_archivos(
                    archivo_liquidacion, archivo_masterdata
                )
                
                if resultado_df is not None:
                    st.success("‚úÖ ¬°Procesamiento completado exitosamente!")
                    
                    # Mostrar estad√≠sticas
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("üë• Empleados", len(liquidacion_df))
                    
                    with col2:
                        st.metric("üìä Registros MASTERDATA", len(masterdata_df))
                    
                    with col3:
                        matches = 0
                        if 'SAP' in liquidacion_df.columns and 'N¬∫ pers.' in resultado_df.columns:
                            matches = resultado_df['N¬∫ pers.'].notna().sum()
                        st.metric("üîó Matches encontrados", matches)
                    
                    # Mostrar informaci√≥n de columnas duplicadas si las hubo
                    if any([df.columns.duplicated().any() for df in [resultado_df, liquidacion_df, masterdata_df] if df is not None]):
                        st.info("‚ÑπÔ∏è Se detectaron y limpiaron columnas duplicadas autom√°ticamente")
                    
                    # Pesta√±as para mostrar datos
                    tab1, tab2 = st.tabs(["üìä Vista Previa", "üìÅ Descargar"])
                    
                    with tab1:
                        st.subheader("üîç Vista previa de los datos procesados")
                        
                        # Selector de hoja
                        hoja_seleccionada = st.selectbox(
                            "Selecciona qu√© datos ver:",
                            ["Datos Combinados", "Solo Liquidaci√≥n", "Solo MASTERDATA"]
                        )
                        
                        try:
                            if hoja_seleccionada == "Datos Combinados":
                                st.write(f"**Total de columnas:** {len(resultado_df.columns)}")
                                st.write(f"**Primeras 5 columnas:** {list(resultado_df.columns[:5])}")
                                st.dataframe(resultado_df.head(100), use_container_width=True)
                            elif hoja_seleccionada == "Solo Liquidaci√≥n":
                                st.write(f"**Total de columnas:** {len(liquidacion_df.columns)}")
                                st.write(f"**Primeras 5 columnas:** {list(liquidacion_df.columns[:5])}")
                                st.dataframe(liquidacion_df.head(100), use_container_width=True)
                            else:
                                st.write(f"**Total de columnas:** {len(masterdata_df.columns)}")
                                st.write(f"**Primeras 5 columnas:** {list(masterdata_df.columns[:5])}")
                                st.dataframe(masterdata_df.head(100), use_container_width=True)
                        except Exception as e:
                            st.error(f"Error al mostrar DataFrame: {str(e)}")
                            st.error("Verifica que no haya caracteres especiales en los nombres de columnas")
                    
                    with tab2:
                        st.subheader("üì• Descargar archivo procesado")
                        st.markdown("El archivo Excel contendr√° EXACTAMENTE 2 hojas:")
                        st.markdown("- **Netos**: Con columnas NETO, Valor, SAP, C√âDULA, NOMBRE, REGIONAL, CE_COSTE, SALARIO, F. ING, CARGO, NIVEL")
                        st.markdown("- **Convertida**: Con columnas C√ìDIGO, CONCEPTO, CANTIDAD, VALOR, SAP, C√âDULA, NOMBRE, SALARIO, F. INGRESO, CARGO, NIVEL")
                        
                        # Generar archivo para descarga
                        excel_file = crear_excel_descarga(resultado_df, liquidacion_df, masterdata_df)
                        
                        if excel_file:
                            st.download_button(
                                label="üìÅ Descargar Excel procesado (SOLO 2 hojas)",
                                data=excel_file.getvalue(),
                                file_name=f"Liquidacion_2hojas_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                type="primary"
                            )
                        else:
                            st.error("‚ùå Error al generar el archivo de descarga")
                            
        else:
            st.warning("‚ö†Ô∏è Por favor carga ambos archivos antes de procesar.")
    
    # Informaci√≥n adicional en el sidebar
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    ### ‚ö†Ô∏è IMPORTANTE:
    - El Excel generado tendr√° EXACTAMENTE 2 hojas
    - Hoja "Netos": Datos principales de empleados  
    - Hoja "Convertida": Desglose de conceptos
    - No se generar√°n hojas adicionales
    """)
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    <div style='text-align: center; font-size: 10px; color: #888;'>
        N√≥mina 2025<br>
        Desarrollado by @jeysshon<br>
        üéØ Versi√≥n CORREGIDA - Solo 2 hojas
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
