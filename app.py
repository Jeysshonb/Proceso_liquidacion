import streamlit as st
import pandas as pd
import re
from datetime import datetime
import io
import base64

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Procesador de Liquidaci√≥n y MASTERDATA",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

def limpiar_columnas_duplicadas(df):
    """
    Elimina columnas duplicadas de un DataFrame
    """
    if df is None or df.empty:
        return df
    
    # Verificar si hay columnas duplicadas
    if df.columns.duplicated().any():
        st.warning(f"‚ö†Ô∏è Columnas duplicadas encontradas: {df.columns[df.columns.duplicated()].tolist()}")
        
        # Eliminar columnas duplicadas (mantener la primera)
        df_limpio = df.loc[:, ~df.columns.duplicated()]
        
        st.success(f"‚úÖ DataFrame limpiado: {len(df.columns)} -> {len(df_limpio.columns)} columnas")
        return df_limpio
    
    return df

def parsear_recibo_liquidacion(contenido_archivo):
    """
    Parsea un archivo de recibos de liquidaci√≥n con formato espec√≠fico
    """
    empleados = []
    empleado_actual = {}
    
    lineas = contenido_archivo.split('\n')
    
    for i, linea in enumerate(lineas):
        linea = linea.strip()
        
        # Nueva p√°gina o nuevo empleado
        if linea.startswith('Pagina:'):
            if empleado_actual:  # Guardar empleado anterior si existe
                empleados.append(empleado_actual.copy())
                empleado_actual = {}
            continue
        
        # Saltar l√≠neas vac√≠as y encabezados
        if not linea or linea.startswith('RECIBO DE PAGO') or linea.startswith('Fecha:'):
            continue
        
        # Extraer informaci√≥n del empleado
        try:
            # N√∫mero de personal y c√©dula
            if 'Nm. Personal' in linea and 'Cedula Ident' in linea:
                personal_match = re.search(r'Nm\. Personal\.+(\d+)', linea)
                cedula_match = re.search(r'Cedula Ident\.+ (\d+)', linea)
                
                if personal_match:
                    empleado_actual['SAP'] = int(personal_match.group(1))
                if cedula_match:
                    empleado_actual['CEDULA'] = int(cedula_match.group(1))
            
            # Nombre del empleado y sueldo b√°sico
            elif 'Empleado' in linea and 'Sueldo Bsico' in linea:
                nombre_match = re.search(r'Empleado \.+ (.+?)\s+Sueldo Bsico\.+\s*([\d\.,]+)', linea)
                if nombre_match:
                    empleado_actual['NOMBRE'] = nombre_match.group(1).strip()
                    sueldo_str = nombre_match.group(2).replace('.', '').replace(',', '.')
                    try:
                        empleado_actual['SALARIO'] = float(sueldo_str)
                    except:
                        empleado_actual['SALARIO'] = 0
            
            # Compa√±√≠a y fecha de nacimiento
            elif 'Compaa' in linea and 'Fecha Nacto' in linea:
                compania_match = re.search(r'Compaa\.+ (.+?)\s+Fecha Nacto\.+(.+)', linea)
                if compania_match:
                    empleado_actual['COMPANIA'] = compania_match.group(1).strip()
                    empleado_actual['FECHA_NACIMIENTO'] = compania_match.group(2).strip()
            
            # Divisi√≥n y fecha de ingreso
            elif 'Divisin' in linea and 'Fecha Ingreso' in linea:
                division_match = re.search(r'Divisin\.+ (.+?)\s+Fecha Ingreso\.+(.+)', linea)
                if division_match:
                    empleado_actual['REGIONAL'] = division_match.group(1).strip()
                    empleado_actual['F_ING'] = division_match.group(2).strip()
            
            # Subdivisi√≥n y relaci√≥n laboral
            elif 'Subdivisin' in linea and 'Relacin Lab' in linea:
                subdivision_match = re.search(r'Subdivisin\.+ (.+?)\s+Relacin Lab\.+(.+)', linea)
                if subdivision_match:
                    empleado_actual['SUBDIVISION'] = subdivision_match.group(1).strip()
                    empleado_actual['CARGO'] = subdivision_match.group(2).strip()
            
            # Centro de coste
            elif 'Ce.coste' in linea:
                ce_coste_match = re.search(r'Ce\.coste\.+(\d+)', linea)
                if ce_coste_match:
                    empleado_actual['CE_COSTE'] = int(ce_coste_match.group(1))
            
            # Buscar conceptos y valores (l√≠neas que terminan con n√∫meros)
            elif re.search(r'^[A-Za-z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë\s\.]+\s+([\d\.,\-]+)$', linea):
                concepto_match = re.match(r'^(.+?)\s+([\d\.,\-]+)$', linea)
                if concepto_match:
                    concepto = concepto_match.group(1).strip()
                    valor_str = concepto_match.group(2).replace('.', '').replace(',', '.')
                    try:
                        valor = float(valor_str)
                        # Limpiar el nombre del concepto
                        concepto_limpio = re.sub(r'[^\w\s]', '', concepto).strip().upper().replace(' ', '_')
                        if concepto_limpio:
                            empleado_actual[f'CONCEPTO_{concepto_limpio}'] = valor
                    except:
                        pass
        
        except Exception as e:
            # Continuar con la siguiente l√≠nea si hay error en el parsing
            continue
    
    # Agregar √∫ltimo empleado
    if empleado_actual:
        empleados.append(empleado_actual)
    
    if len(empleados) == 0:
        return pd.DataFrame()
    
    # Convertir a DataFrame
    df = pd.DataFrame(empleados)
    
    # Calcular valor neto si no existe
    if 'NETO' not in df.columns:
        # Buscar columnas de conceptos para calcular el neto
        conceptos_cols = [col for col in df.columns if col.startswith('CONCEPTO_')]
        if conceptos_cols:
            df['NETO'] = df[conceptos_cols].sum(axis=1, skipna=True)
        elif 'SALARIO' in df.columns:
            df['NETO'] = df['SALARIO']
    
    return df

def procesar_archivos(archivo_liquidacion, archivo_masterdata):
    """
    Procesa los archivos de Liquidaci√≥n y MASTERDATA
    """
    try:
        # 1. Parsear archivo de Liquidaci√≥n
        contenido_liquidacion = archivo_liquidacion.getvalue().decode('utf-8', errors='ignore')
        liquidacion_df = parsear_recibo_liquidacion(contenido_liquidacion)
        
        if liquidacion_df.empty:
            st.error("No se pudieron extraer datos del archivo de liquidaci√≥n")
            return None, None, None
        
        # 2. Leer archivo MASTERDATA
        try:
            masterdata_df = pd.read_excel(archivo_masterdata, engine='openpyxl')
        except:
            try:
                # Si falla openpyxl, intentar con otros motores
                masterdata_df = pd.read_excel(archivo_masterdata)
            except Exception as e:
                st.error(f"Error al leer MASTERDATA: {str(e)}")
                return None, None, None
        
        # 3. Limpiar nombres de columnas
        liquidacion_df.columns = liquidacion_df.columns.str.strip()
        masterdata_df.columns = masterdata_df.columns.str.strip()
        
        # 4. Buscar columnas de uni√≥n
        sap_col_liquidacion = 'SAP' if 'SAP' in liquidacion_df.columns else None
        sap_col_masterdata = 'N¬∫ pers.' if 'N¬∫ pers.' in masterdata_df.columns else None
        
        # 5. Realizar merge si es posible
        if sap_col_liquidacion and sap_col_masterdata:
            liquidacion_df[sap_col_liquidacion] = pd.to_numeric(liquidacion_df[sap_col_liquidacion], errors='coerce')
            masterdata_df[sap_col_masterdata] = pd.to_numeric(masterdata_df[sap_col_masterdata], errors='coerce')
            
            resultado_df = pd.merge(
                liquidacion_df, 
                masterdata_df, 
                left_on=sap_col_liquidacion, 
                right_on=sap_col_masterdata, 
                how='left',
                suffixes=('_liquidacion', '_masterdata')
            )
            
            # ‚úÖ SOLUCI√ìN: Limpiar columnas duplicadas despu√©s del merge
            resultado_df = limpiar_columnas_duplicadas(resultado_df)
            
        else:
            resultado_df = liquidacion_df
            # Tambi√©n limpiar liquidacion_df por si acaso
            resultado_df = limpiar_columnas_duplicadas(resultado_df)
        
        # Tambi√©n limpiar los otros DataFrames
        liquidacion_df = limpiar_columnas_duplicadas(liquidacion_df)
        masterdata_df = limpiar_columnas_duplicadas(masterdata_df)
        
        return resultado_df, liquidacion_df, masterdata_df
        
    except Exception as e:
        st.error(f"Error durante el procesamiento: {str(e)}")
        st.error(f"Detalles del error: {type(e).__name__}")
        import traceback
        st.error(f"Traceback: {traceback.format_exc()}")
        return None, None, None

def crear_excel_descarga(resultado_df, liquidacion_df, masterdata_df):
    """
    Crea un archivo Excel para descargar - Basado en el c√≥digo Python exitoso
    """
    output = io.BytesIO()
    
    try:
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            
            if resultado_df is not None:
                # Limpiar columnas duplicadas antes de escribir
                resultado_df_limpio = limpiar_columnas_duplicadas(resultado_df)
                
                # Hoja con datos combinados
                resultado_df_limpio.to_excel(writer, sheet_name='Datos_Combinados', index=False)
                
                # Crear hoja "Netos" similar al archivo original - mismo formato que el c√≥digo Python
                netos_df = resultado_df_limpio.copy()
                
                # Reorganizar columnas para que se parezca al formato original
                columnas_netos = []
                if 'NETO' in netos_df.columns:
                    columnas_netos.append('NETO')
                if 'SALARIO' in netos_df.columns:
                    columnas_netos.append('SALARIO')
                
                # Buscar columna SAP
                sap_col = None
                for col in ['SAP']:
                    if col in netos_df.columns:
                        columnas_netos.append(col)
                        sap_col = col
                        break
                
                # Agregar otras columnas importantes
                for col in ['CEDULA', 'NOMBRE', 'REGIONAL', 'CE_COSTE', 'F_ING', 'CARGO']:
                    if col in netos_df.columns:
                        columnas_netos.append(col)
                
                # Agregar columnas restantes
                for col in netos_df.columns:
                    if col not in columnas_netos:
                        columnas_netos.append(col)
                
                netos_df = netos_df[columnas_netos]
                netos_df.to_excel(writer, sheet_name='Netos', index=False)
                
            else:
                # Si no hay merge, solo datos de liquidaci√≥n
                liquidacion_df_limpio = limpiar_columnas_duplicadas(liquidacion_df)
                liquidacion_df_limpio.to_excel(writer, sheet_name='Liquidacion', index=False)
            
            # Hoja MASTERDATA
            if masterdata_df is not None:
                masterdata_df_limpio = limpiar_columnas_duplicadas(masterdata_df)
                masterdata_df_limpio.to_excel(writer, sheet_name='MASTERDATA', index=False)
            
            # Informaci√≥n del procesamiento - mismo formato que el c√≥digo Python original
            info_data = {
                'Informaci√≥n': [
                    'Archivo procesado el:',
                    'Empleados en Liquidaci√≥n:',
                    'Registros en MASTERDATA:',
                    'Empleados con match:',
                    'Columna de uni√≥n Liquidaci√≥n:',
                    'Columna de uni√≥n MASTERDATA:'
                ],
                'Valor': [
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    len(liquidacion_df) if liquidacion_df is not None else 0,
                    len(masterdata_df) if masterdata_df is not None else 0,
                    resultado_df[resultado_df.columns[resultado_df.columns.str.contains('N¬∫ pers.', na=False)]].iloc[:, 0].notna().sum() if resultado_df is not None and any(resultado_df.columns.str.contains('N¬∫ pers.', na=False)) else 0,
                    'SAP' if liquidacion_df is not None and 'SAP' in liquidacion_df.columns else 'No encontrada',
                    'N¬∫ pers.' if masterdata_df is not None and 'N¬∫ pers.' in masterdata_df.columns else 'No encontrada'
                ]
            }
            
            info_df = pd.DataFrame(info_data)
            info_df.to_excel(writer, sheet_name='Info_Procesamiento', index=False)
        
        output.seek(0)
        return output
        
    except Exception as e:
        st.error(f"Error al crear archivo Excel: {str(e)}")
        return None

def main():
    # T√≠tulo principal
    st.title("üìä Procesador de Liquidaci√≥n y MASTERDATA")
    st.markdown("---")
    
    # Descripci√≥n
    st.markdown("""
    ### üéØ ¬øQu√© hace esta aplicaci√≥n?
    Esta herramienta procesa archivos de liquidaci√≥n en formato de recibos de pago y los combina con datos maestros (MASTERDATA) para generar reportes estructurados en Excel.
    
    ### üìã Funcionalidades:
    - ‚úÖ Extrae informaci√≥n de recibos de liquidaci√≥n (formato texto)
    - ‚úÖ Combina con datos de MASTERDATA (Excel/XLSB)
    - ‚úÖ Genera archivo Excel con m√∫ltiples hojas
    - ‚úÖ Interfaz web f√°cil de usar
    - ‚úÖ **Detecci√≥n y limpieza autom√°tica de columnas duplicadas**
    """)
    
    # Sidebar para carga de archivos
    st.sidebar.header("üìÅ Cargar Archivos")
    
    # Archivo de Liquidaci√≥n
    archivo_liquidacion = st.sidebar.file_uploader(
        "üìÑ Archivo de Liquidaci√≥n (.txt)",
        type=['txt'],
        help="Selecciona el archivo de recibos de liquidaci√≥n en formato texto"
    )
    
    # Archivo MASTERDATA
    archivo_masterdata = st.sidebar.file_uploader(
        "üìä Archivo MASTERDATA (.xlsx)",
        type=['xlsx'],
        help="Selecciona el archivo con los datos maestros (solo formato .xlsx)"
    )
    
    # Bot√≥n de procesamiento
    if st.sidebar.button("üöÄ Procesar Archivos", type="primary"):
        if archivo_liquidacion is not None and archivo_masterdata is not None:
            with st.spinner('‚è≥ Procesando archivos...'):
                resultado_df, liquidacion_df, masterdata_df = procesar_archivos(
                    archivo_liquidacion, archivo_masterdata
                )
                
                if resultado_df is not None:
                    st.success("‚úÖ ¬°Procesamiento completado exitosamente!")
                    
                    # Mostrar estad√≠sticas
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("üë• Empleados", len(liquidacion_df))
                    
                    with col2:
                        st.metric("üìä Registros MASTERDATA", len(masterdata_df))
                    
                    with col3:
                        matches = 0
                        if 'SAP' in liquidacion_df.columns and 'N¬∫ pers.' in resultado_df.columns:
                            matches = resultado_df['N¬∫ pers.'].notna().sum()
                        st.metric("üîó Matches encontrados", matches)
                    
                    with col4:
                        st.metric("üìã Total columnas", len(resultado_df.columns))
                    
                    # Mostrar informaci√≥n de columnas duplicadas si las hubo
                    if any([df.columns.duplicated().any() for df in [resultado_df, liquidacion_df, masterdata_df] if df is not None]):
                        st.info("‚ÑπÔ∏è Se detectaron y limpiaron columnas duplicadas autom√°ticamente")
                    
                    # Pesta√±as para mostrar datos
                    tab1, tab2, tab3 = st.tabs(["üìä Vista Previa", "üìà Estad√≠sticas", "üìÅ Descargar"])
                    
                    with tab1:
                        st.subheader("üîç Vista previa de los datos procesados")
                        
                        # Selector de hoja
                        hoja_seleccionada = st.selectbox(
                            "Selecciona qu√© datos ver:",
                            ["Datos Combinados", "Solo Liquidaci√≥n", "Solo MASTERDATA"]
                        )
                        
                        try:
                            if hoja_seleccionada == "Datos Combinados":
                                # Mostrar informaci√≥n de columnas para diagn√≥stico
                                st.write(f"**Total de columnas:** {len(resultado_df.columns)}")
                                st.write(f"**Primeras 5 columnas:** {list(resultado_df.columns[:5])}")
                                st.dataframe(resultado_df.head(100), use_container_width=True)
                            elif hoja_seleccionada == "Solo Liquidaci√≥n":
                                st.write(f"**Total de columnas:** {len(liquidacion_df.columns)}")
                                st.write(f"**Primeras 5 columnas:** {list(liquidacion_df.columns[:5])}")
                                st.dataframe(liquidacion_df.head(100), use_container_width=True)
                            else:
                                st.write(f"**Total de columnas:** {len(masterdata_df.columns)}")
                                st.write(f"**Primeras 5 columnas:** {list(masterdata_df.columns[:5])}")
                                st.dataframe(masterdata_df.head(100), use_container_width=True)
                        except Exception as e:
                            st.error(f"Error al mostrar DataFrame: {str(e)}")
                            st.error("Verifica que no haya caracteres especiales en los nombres de columnas")
                    
                    with tab2:
                        st.subheader("üìà Estad√≠sticas del procesamiento")
                        
                        # Informaci√≥n de liquidaci√≥n
                        st.markdown("#### üí∞ Datos de Liquidaci√≥n")
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            if 'SALARIO' in liquidacion_df.columns:
                                salario_promedio = liquidacion_df['SALARIO'].mean()
                                st.metric("üíµ Salario Promedio", f"${salario_promedio:,.0f}")
                        
                        with col2:
                            if 'REGIONAL' in liquidacion_df.columns:
                                regionales = liquidacion_df['REGIONAL'].nunique()
                                st.metric("üè¢ Regionales", regionales)
                        
                        # Top regionales
                        if 'REGIONAL' in liquidacion_df.columns:
                            st.markdown("#### üèÜ Top Regionales por Empleados")
                            top_regionales = liquidacion_df['REGIONAL'].value_counts().head(10)
                            st.bar_chart(top_regionales)
                    
                    with tab3:
                        st.subheader("üì• Descargar archivo procesado")
                        st.markdown("Haz clic en el bot√≥n para descargar el archivo Excel con todos los datos procesados.")
                        
                        # Generar archivo para descarga
                        excel_file = crear_excel_descarga(resultado_df, liquidacion_df, masterdata_df)
                        
                        if excel_file:
                            st.download_button(
                                label="üìÅ Descargar Excel procesado",
                                data=excel_file.getvalue(),
                                file_name=f"Liquidacion_procesada_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                type="primary"
                            )
                            
                            st.info("üí° El archivo contiene las siguientes hojas:\n- **Datos_Combinados**: Merge completo\n- **Netos**: Formato ordenado\n- **MASTERDATA**: Datos maestros\n- **Info_Procesamiento**: Resumen")
                        else:
                            st.error("‚ùå Error al generar el archivo de descarga")
                            
        else:
            st.warning("‚ö†Ô∏è Por favor carga ambos archivos antes de procesar.")
    
    # Informaci√≥n adicional en el sidebar
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    ### üí° Consejos:
    - El archivo de liquidaci√≥n debe ser formato texto (.txt) de JMC
    - La aplicaci√≥n detecta autom√°ticamente las columnas de uni√≥n SAP
    - Optimizado para procesar recibos de pago de Jer√≥nimo Martins Colombia
    - **Limpia autom√°ticamente columnas duplicadas**
    - Interfaz web especializada para n√≥mina de Jer√≥nimo Martins Colombia
    """)
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    <div style='text-align: center; font-size: 10px; color: #888;'>
        N√≥mina 2025<br>
        Desarrollado by @jeysshon<br>
        ‚úÖ Versi√≥n con limpieza de columnas duplicadas
    </div>
    """, unsafe_allow_html=True)
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center'>
        <p>üöÄ Desarrollado para el procesamiento eficiente de datos de liquidaci√≥n</p>
        <p>üìß ¬øNecesitas ayuda? Contacta al equipo de desarrollo</p>
        <p><small>üîß Versi√≥n mejorada con correcci√≥n de columnas duplicadas</small></p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
